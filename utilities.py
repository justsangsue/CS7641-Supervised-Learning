import csv
import numpy as np
import pandas as pd
import pickle
import pylab as plt
import random
import time
from functools import wraps
from matplotlib.font_manager import FontProperties
from pybrain.structure import FeedForwardNetwork, LinearLayer, SigmoidLayer
from pybrain.structure import TanhLayer, FullConnection
from pybrain.datasets import ClassificationDataSet
from pybrain.utilities import percentError
from pybrain.tools.shortcuts import buildNetwork
from pybrain.supervised.trainers import BackpropTrainer
from sklearn import neighbors
from sklearn import preprocessing
from sklearn import tree
from sklearn import svm
from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier
from sklearn.metrics import accuracy_score

def timeit(func):
	""" Decorator function used to time execution."""
	@wraps(func)
	def timed_function(*args, **kwargs):
	    start = time.time()
	    output = func(*args, **kwargs)
	    end = time.time()
	    print("%s execution time: %f secs" % (func.__name__, end - start))
	    return output
	return timed_function


@timeit
def get_learning_curve(estimator, trainx, trainy, testx, testy, cv=1,
                       train_sizes=np.linspace(.1, 1.0, 10)):
    """ Returns the learning curve for scikit lassifiers (no neural nets!), i.e.
    training and test accuracies (not error!).

    The input variables are:
    estimator - the scikit classifier to be used (parameters should alread by set)
    trainx - features of the training data
    trainy - labels of the training data
    testx - features of the test data
    testy - labels of the test data
    cv - the number of trainings to be average for more accurate estimates
    train_sizes - list of training size proportions, from (0.0, 1.0]
                   corresponding to 0% to 100% of the full training set set size

    The return variables are:
    train_sizes - list of the training set (proportional) sizes, i.e. x axis
    average_train_scores - the average training accuracy at each training set size
    average_test_scores - the average test accuracy at each training set size
    """

    cv_train_scores = [[0] * len(train_sizes)]
    cv_test_scores = [[0] * len(train_sizes)]
    for c in range(cv):
        train_scores = []
        test_scores = []
        for ts in train_sizes:
            n_examples = int(round(len(trainx) * ts))
            rows = random.sample(range(len(trainx)), n_examples)
            subx = trainx.iloc[rows, ]
            suby = trainy.iloc[rows, ]
            start = time.time()
            estimator.fit(subx, suby)
            print("training time: {} secs".format(time.time() - start))
            current_train_score = estimator.score(subx, suby)
            current_test_score = estimator.score(testx, testy)
            train_scores.append(current_train_score)
            test_scores.append(current_test_score)
        cv_train_scores.append(train_scores)
        cv_test_scores.append(test_scores)
    average_train_scores = [sum(i) / cv for i in zip(*cv_train_scores)]
    average_test_scores = [sum(i) / cv for i in zip(*cv_test_scores)]
    return train_sizes, average_train_scores, average_test_scores

def accuracy_plot(data, title=''):
	ts, te, ve = data
	plt.plot(ts, te, "r-", ts, ve, "b-")
	plt.ylabel("Accuracy (out of 1)")
	plt.xlabel("Fractional Training Set Size")
	plt.title(title)
	plt.legend(["Training Accuracy", "Test Accuracy"], loc="best",
				fancybox=True, shadow=True,
				prop=FontProperties().set_size("small"))
	plt.show()

def err_plot(data, title=''):
    """ Make a plot of the training and test error given the data
    resulting from get_learning_curve() or ann_learning_curve().

    Input variables are:
    data - a list of the three outputs from get_learning_curve()
           or ann_learning_curve()
    title - the title of the plot
    """
    ts, te, ve = data
    te = [1-x for x in te]  # convert to error
    ve = [1-x for x in ve]  # error
    plt.plot(ts, te, "r-", ts, ve, "b-")
    plt.ylabel("Error (out of 1)")
    plt.xlabel("Fractional Training Set Size")
    plt.title(title)
    plt.legend(["Training error", "Test error"], loc="best",
               fancybox=True, shadow=True,
               prop=FontProperties().set_size("small"))
    plt.show()

def plot_learning_curves(result, title, disp="accuracy"):
	""" Automatically plots the learning curve data generated by
	get_learning_curve() or ann_learning_curve() functions,
	and also from the run_all() function. If you run the run_all() function,
	this will save data to be read by this function.
	disp is either "accuracy" or "error"
	"""
	with open(result, "rb") as f:
		data = pickle.load(f)
	if disp == "accuracy":
		accuracy_plot(data, title=title)
	elif disp == "error":
		err_plot(data, title=title)

def load_data(file_path):
	""" Load dataset. Return variables are:
	trainx - features of the training set
	trainy - labels of the training set
	testx - features of the test set
	testy - labels of the test set
	"""

	df = pd.read_csv(file_path)
	# Optionally sub-sample, then
	df.fillna(value=0, inplace=True)
	cols = list(df.columns.values) 
	cols.pop(cols.index("CLASS")) 
	df = df[cols+["CLASS"]]
	rows = random.sample(df.index.tolist(), 30000)
	df = df.iloc[rows, 1:]

	# Perform a 4:1 split for training and test data
	msk = np.random.rand(len(df)) < 0.8
	trainx = df.iloc[msk, :-1]
	trainy = df.iloc[msk, -1]
	testx = df.iloc[~msk, :-1]
	testy = df.iloc[~msk, -1]

	return trainx, trainy, testx, testy

def load_data_medicalcost(file_path):

	df = pd.read_csv(file_path)
	df.fillna(value=0, inplace=True)
	rows = random.sample(df.index.tolist(), 1000)
	df = df.iloc[rows, 1:]

	# Split charges into 5 bins
	gap = df["charges"].max()/5.
	bins = [0, gap, gap*2., gap*3., gap*4., gap*5.]
	df["charges_classified"] = pd.cut(df["charges"], bins=bins, labels=[0, 1, 2, 3, 4])
	df.drop(["charges"], 1, inplace=True)

	# Perform a 4:1 split for training and test data
	msk = np.random.rand(len(df)) < 0.8
	trainx = df.iloc[msk, :-1]
	trainy = df.iloc[msk, -1]
	testx = df.iloc[~msk, :-1]
	testy = df.iloc[~msk, -1]

	return trainx, trainy, testx, testy



